{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mufa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/mufa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mufa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialization for HateSpeechRecognition\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import t\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_kfold_cv(clf, param_grid, X, y, k1=10, k2=3):\n",
    "    \n",
    "    err = []\n",
    "    kfold = KFold(n_splits=k1, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Outer loop\n",
    "    for ind_train, ind_test in kfold.split(X):\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = X[ind_train], y[ind_train], X[ind_test], y[ind_test]\n",
    "        \n",
    "        # Inner loop\n",
    "        inn = GridSearchCV(clf,param_grid,n_jobs=5, cv=StratifiedKFold(n_splits=5, \n",
    "                                              random_state=42).split(X_train, y_train), \n",
    "                           verbose=2).fit(X_train, y_train)\n",
    "        \n",
    "        # Prediction based on the best selected params, the ones that minimize average error\n",
    "        h = inn.best_estimator_.fit(X_train, y_train).predict(X_test)\n",
    "        \n",
    "        err.append(zero_one_loss(y_test, h))\n",
    "        print(classification_report( y_test, h ))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(rgx_list, text):\n",
    "    new_text = text\n",
    "    for rgx_match in rgx_list:\n",
    "        new_text = re.sub(rgx_match, '', new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_words(content):\n",
    "    ret_list = []\n",
    "    fdist2 = nltk.FreqDist(content)\n",
    "    most_list = fdist2.most_common(75)\n",
    "    for x in most_list:\n",
    "        ret_list.append(x)\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "#other_exclusions = [\"#ff\", \"ff\", \"rt\",\"!\",\":\",\"...\",\".\",\"-\",\"&\",\"?\"]\n",
    "#stopwords_list.extend(other_exclusions)\n",
    "\n",
    "dataset = pd.read_csv(\"dataset/labeled_data.csv\")\n",
    "\n",
    "tweets = dataset.tweet\n",
    "\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "\n",
    "#ps.stem(dataset)\n",
    "\n",
    "#Text cleaning and tokenization, then stemming then POS tagging\n",
    "filtered_tweets=[];\n",
    "tweet_tags = [];\n",
    "filtered_tweets_stemmed=[];\n",
    "common_words_prepare=[];\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet = clean_text([\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\".*@.*:\",\"&#*\\w*\",\"@[\\w\\-]+\",\"[^\\w\\s]\"],tweet)\n",
    "    tweet = tweet.lower()\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    common_words = get_common_words(word_tokens)\n",
    "    for word in common_words:\n",
    "        common_words_prepare.append(word)\n",
    "    filtered_tweets.append([word for word in word_tokens if not word in stopwords_list])\n",
    "    filtered_tweets_stemmed.append([ps.stem(word) for word in word_tokens if not word in stopwords_list])\n",
    "    \n",
    "for tweet in filtered_tweets:\n",
    "    tweet_tags.append(nltk.pos_tag(tweet))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Izbacivanje frequent wordsa\n",
    "\n",
    "common_words = get_common_words(common_words_prepare)\n",
    "#for word in filtered_tweets[1:100]:\n",
    "#    print(word)\n",
    "common = []\n",
    "for word in common_words[1:50]:\n",
    "   common.append(word[0][0])\n",
    "\n",
    "filtered_tweets_no_common = [];\n",
    "filtered_tweets_no_common_stemmed = [];\n",
    "for line in filtered_tweets:\n",
    "    filtered_tweets_no_common.append([word for word in line if not word in common])\n",
    "    filtered_tweets_no_common_stemmed.append([ps.stem(word) for word in line if not word in common])\n",
    "#print(\"---------------------------\")\n",
    "#for word in filtered_tweets_no_common[1:100]:\n",
    "#    print(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating TfIdf vectorizer\n",
    "ftss=[]\n",
    "for tweet in filtered_tweets_no_common_stemmed:\n",
    "    ftss.append(' '.join(tweet))\n",
    "\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(ngram_range=(1,3),lowercase=False,max_features=1000,smooth_idf=False,norm=None,max_df=0.75,min_df=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(ftss).toarray()\n",
    "Y = dataset['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42, test_size=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 69.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.48      0.12      0.19       164\n",
      "          1       0.84      0.97      0.90      1905\n",
      "          2       0.79      0.44      0.56       410\n",
      "\n",
      "avg / total       0.80      0.82      0.80      2479\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 69.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.16      0.22       127\n",
      "          1       0.84      0.97      0.90      1927\n",
      "          2       0.82      0.42      0.56       425\n",
      "\n",
      "avg / total       0.82      0.83      0.81      2479\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 67.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.10      0.17       136\n",
      "          1       0.84      0.97      0.90      1916\n",
      "          2       0.81      0.45      0.58       427\n",
      "\n",
      "avg / total       0.82      0.84      0.81      2479\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 69.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.14      0.21       145\n",
      "          1       0.85      0.97      0.90      1917\n",
      "          2       0.79      0.48      0.59       416\n",
      "\n",
      "avg / total       0.82      0.84      0.81      2478\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 70.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.16      0.26       171\n",
      "          1       0.83      0.98      0.90      1894\n",
      "          2       0.83      0.41      0.55       413\n",
      "\n",
      "avg / total       0.83      0.83      0.80      2478\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 67.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.15      0.23       141\n",
      "          1       0.85      0.97      0.91      1930\n",
      "          2       0.85      0.49      0.62       407\n",
      "\n",
      "avg / total       0.83      0.85      0.82      2478\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 69.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.16      0.25       154\n",
      "          1       0.84      0.97      0.90      1915\n",
      "          2       0.80      0.45      0.57       409\n",
      "\n",
      "avg / total       0.82      0.83      0.81      2478\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 66.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.13      0.21       135\n",
      "          1       0.84      0.97      0.90      1907\n",
      "          2       0.82      0.45      0.58       436\n",
      "\n",
      "avg / total       0.82      0.83      0.81      2478\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 72.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.13      0.21       133\n",
      "          1       0.86      0.97      0.91      1937\n",
      "          2       0.81      0.49      0.61       408\n",
      "\n",
      "avg / total       0.84      0.85      0.82      2478\n",
      "\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  15 out of  15 | elapsed: 68.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.13      0.20       124\n",
      "          1       0.86      0.98      0.91      1942\n",
      "          2       0.86      0.50      0.63       412\n",
      "\n",
      "avg / total       0.84      0.85      0.83      2478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "C = [ 2e-2, 2e-1, 2e-0]\n",
    "gama = [ 2e-2, 2e-1, 2e-0]\n",
    "param = [{'svc__kernel': ['rbf'], 'svc__C': C}]\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "scale = StandardScaler()\n",
    "pipeline = Pipeline([('scaler', scale), ('svc', clf)])\n",
    "\n",
    "svm_err = nested_kfold_cv(pipeline, param, X, Y)\n",
    "#param_grid = [{}] \n",
    "#grid_search = GridSearchCV(pipeline, \n",
    "#                           param_grid,\n",
    "#                          n_jobs = 5,\n",
    "#                           cv=StratifiedKFold(n_splits=5, \n",
    "#                                              random_state=42).split(X_train, y_train), \n",
    "#                           verbose=2)\n",
    "#model = grid_search.fit(X_train,y_train)\n",
    "#y_pred = model.predict(X_test)\n",
    "#report = classification_report( y_test, y_pred )\n",
    "#print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.10      0.17       164\n",
      "          1       0.85      0.97      0.90      1905\n",
      "          2       0.80      0.54      0.65       410\n",
      "\n",
      "avg / total       0.82      0.84      0.81      2479\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.12      0.19       127\n",
      "          1       0.86      0.97      0.91      1927\n",
      "          2       0.80      0.50      0.62       425\n",
      "\n",
      "avg / total       0.83      0.85      0.82      2479\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.45      0.10      0.17       136\n",
      "          1       0.86      0.97      0.91      1916\n",
      "          2       0.81      0.55      0.66       427\n",
      "\n",
      "avg / total       0.83      0.85      0.83      2479\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.15      0.24       145\n",
      "          1       0.87      0.96      0.91      1917\n",
      "          2       0.80      0.58      0.67       416\n",
      "\n",
      "avg / total       0.84      0.85      0.83      2478\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.13      0.21       171\n",
      "          1       0.84      0.97      0.90      1894\n",
      "          2       0.80      0.50      0.62       413\n",
      "\n",
      "avg / total       0.82      0.83      0.81      2478\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.12      0.20       141\n",
      "          1       0.86      0.97      0.91      1930\n",
      "          2       0.82      0.56      0.66       407\n",
      "\n",
      "avg / total       0.84      0.86      0.83      2478\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.12      0.19       154\n",
      "          1       0.86      0.97      0.91      1915\n",
      "          2       0.79      0.55      0.65       409\n",
      "\n",
      "avg / total       0.82      0.84      0.82      2478\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.11      0.17       135\n",
      "          1       0.85      0.96      0.90      1907\n",
      "          2       0.80      0.55      0.65       436\n",
      "\n",
      "avg / total       0.82      0.84      0.82      2478\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.11      0.17       133\n",
      "          1       0.86      0.97      0.91      1937\n",
      "          2       0.79      0.55      0.65       408\n",
      "\n",
      "avg / total       0.83      0.85      0.83      2478\n",
      "\n",
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  35 out of  35 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.17      0.26       124\n",
      "          1       0.88      0.98      0.92      1942\n",
      "          2       0.86      0.58      0.70       412\n",
      "\n",
      "avg / total       0.86      0.87      0.85      2478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "C = [2e-3, 2e-2, 2e-1, 2e-0, 2e-1, 2e-2, 2e-3]\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "clf = LogisticRegression(multi_class='ovr',solver='newton-cg')\n",
    "pipeline = Pipeline([('scaler', std_scaler)  , ('clf', clf)])\n",
    "param = [{'clf__C': C}]\n",
    "\n",
    "logreg_err = nested_kfold_cv(pipeline, param, X, Y)\n",
    "\n",
    "\n",
    "\n",
    "#TODO: logicstic regression, model selection, kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "p-value =  5.310675075060413e-05 , hipoteza se odbacuje.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel as paired_t_test\n",
    "\n",
    "t_stat, p_val = paired_t_test(logreg_err, svm_err)\n",
    "\n",
    "if p_val <= 0.05:\n",
    "    print('\\np-value = ', p_val, ', hipoteza se odbacuje.')\n",
    "else:\n",
    "    print('\\np-value = ', p_val, ', hipoteza se ne odbacuje.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Some of yall just \"popular\" cuz of yall name ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4531</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>@Pepper_Redbone @Yankees @Mets Exactly by folk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19341</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @dril: night time falls. im \"corie latin\" n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12381</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Jihadis taunting America &amp;amp; spreading paran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18453</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @WhatTheFFacts: Actor Charlie Sheen once bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11303</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>I want Oreos!! Who can help me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2342</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@05proFESSOR I bet he's a Starbucks queer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15968</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Ih8lightskins__: only a black man can make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6599</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@kieffer_jason @zach_smith98 @NathannDevlin so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21524</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Someone shut this beaner up please.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5777</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@billyeichner Since @TomCruise will be a hoser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>#porn,#android,#iphone,#ipad,#sex,#xxx, | #Fis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22367</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Think it's okay to take my property and break ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2768</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Buckm00se Joe Cortez is the ultimate faggot t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14035</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Oomf a hoe. She know she a hoe, I know she a h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22192</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>These bitches is crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20132</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @missyantzah: You can do anything you want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11416</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I would like to apologize to anyone I have cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12618</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Lakers are trash right now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9256</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Everyone calls me \"b\" they be like oh wassup b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6158</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@fucktyler fuck you spear chucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3517</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Huntermoore happy cuz I woke up white and not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9359</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fine ass fat bitch... #TwitterLurking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24148</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>bitches ain&amp;#8217;t shit, and they ain&amp;#8217;t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3914</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Kenny__Wright @itsfrankybitch @yoPapi_chulo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20772</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @wishfulll: Big booty bitches with... \"@Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19207</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @consprcy_carrot: Blow shit up and get fatt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8548</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Can someone get me cheese and crackers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1691</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>&amp;#8220;@__Bino: Looking at nip rings I can't w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14504</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @AmPowerBlog: @velvethammer Parent in Phoen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4260</th>\n",
       "      <td>23612</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yeah at&amp;amp;t needs to get fucked up with this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>15470</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @EmilyWCVB: RIGHT NOW: NewsCenter 5 project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>17578</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @SalamanCode: Proof that thots are retarded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>15053</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @Chvntre: sometimes I wanna upper cut this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>23241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>When you're grinding with a bitch and she's kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>851</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>#firefighter is a job for white trash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>18934</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @ajade___: everybody tryna fuck the next ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>14137</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>People who go to church in Hollywood, CA are a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>22051</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The nations know who we are, but we rather be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4269</th>\n",
       "      <td>549</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Our people\". Now is the time for the Aryan ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>6438</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>@jessitron @Bsilverstrim77 ...in fact were I t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>9389</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Flaw bitches. Flaw bitches everywhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>6051</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@drboycewatkins1 Coons and monkeys like you di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>6281</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@hunterbuch66 @kieffer_jason @sbsylvester yo f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>10585</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I forgot how white trash Texarkana was... Well...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>25010</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>thats top off, pop off, im with my dogs like s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>3994</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@LadyVodkax yer dirty pussy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>19574</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @iDntWearCondoms: 0 hoes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>2733</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@BreeOlson @Gingerbeard66 your a nasty nigger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>3506</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@Hunglikerobby_ that was so gay. And I was tan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>6816</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@marclamonthill will you mention why being cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>18485</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @WolfpackAlan: Oreos: First you twist it, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>12908</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lol bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>15632</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RT @FunSizedYogi: @TheBlackVoice well how else...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4284</th>\n",
       "      <td>2581</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>@BLUE_yupp finger my throbbing pussy slowly as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>5862</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@caykelly16 @MadisonEarhart u guys are fags.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4286</th>\n",
       "      <td>22372</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Thinking bout those oysters at the gator bait ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>6779</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>@longbongchris mk Hun just textith me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4288</th>\n",
       "      <td>12126</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>International law enforcement operation disrup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4289</th>\n",
       "      <td>22690</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Told my dad to go buy cookies for the graduati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4290 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0          21500      3            0                   3        0      1   \n",
       "1           4531      3            0                   0        3      2   \n",
       "2          19341      3            0                   0        3      2   \n",
       "3          12381      3            0                   0        3      2   \n",
       "4          18453      3            0                   0        3      2   \n",
       "5          11303      3            0                   0        3      2   \n",
       "6           2342      3            2                   1        0      0   \n",
       "7          15968      3            0                   3        0      1   \n",
       "8           6599      3            2                   1        0      0   \n",
       "9          21524      3            2                   0        1      0   \n",
       "10          5777      3            0                   1        2      2   \n",
       "11           897      3            0                   3        0      1   \n",
       "12         22367      3            2                   1        0      0   \n",
       "13          2768      3            2                   1        0      0   \n",
       "14         14035      3            0                   3        0      1   \n",
       "15         22192      3            0                   3        0      1   \n",
       "16         20132      3            0                   3        0      1   \n",
       "17         11416      3            3                   0        0      0   \n",
       "18         12618      3            2                   0        1      0   \n",
       "19          9256      3            2                   1        0      0   \n",
       "20          6158      3            3                   0        0      0   \n",
       "21          3517      3            3                   0        0      0   \n",
       "22          9359      3            0                   3        0      1   \n",
       "23         24148      3            0                   3        0      1   \n",
       "24          3914      3            2                   1        0      0   \n",
       "25         20772      3            0                   3        0      1   \n",
       "26         19207      3            0                   3        0      1   \n",
       "27          8548      3            0                   0        3      2   \n",
       "28          1691      3            0                   1        2      2   \n",
       "29         14504      3            0                   0        3      2   \n",
       "...          ...    ...          ...                 ...      ...    ...   \n",
       "4260       23612      3            0                   3        0      1   \n",
       "4261       15470      3            0                   0        3      2   \n",
       "4262       17578      3            2                   0        1      0   \n",
       "4263       15053      3            2                   1        0      0   \n",
       "4264       23241      3            0                   3        0      1   \n",
       "4265         851      3            3                   0        0      0   \n",
       "4266       18934      3            2                   1        0      0   \n",
       "4267       14137      3            2                   0        1      0   \n",
       "4268       22051      3            2                   1        0      0   \n",
       "4269         549      3            3                   0        0      0   \n",
       "4270        6438      3            0                   0        3      2   \n",
       "4271        9389      6            0                   6        0      1   \n",
       "4272        6051      3            2                   1        0      0   \n",
       "4273        6281      3            2                   1        0      0   \n",
       "4274       10585      3            2                   1        0      0   \n",
       "4275       25010      3            0                   2        1      1   \n",
       "4276        3994      3            0                   3        0      1   \n",
       "4277       19574      3            0                   3        0      1   \n",
       "4278        2733      3            2                   1        0      0   \n",
       "4279        3506      3            2                   1        0      0   \n",
       "4280        6816      3            2                   1        0      0   \n",
       "4281       18485      3            0                   2        1      1   \n",
       "4282       12908      6            0                   6        0      1   \n",
       "4283       15632      3            2                   0        1      0   \n",
       "4284        2581      3            0                   3        0      1   \n",
       "4285        5862      3            3                   0        0      0   \n",
       "4286       22372      3            0                   0        3      2   \n",
       "4287        6779      3            0                   0        3      2   \n",
       "4288       12126      3            0                   0        3      2   \n",
       "4289       22690      3            2                   1        0      0   \n",
       "\n",
       "                                                  tweet  \n",
       "0     Some of yall just \"popular\" cuz of yall name ....  \n",
       "1     @Pepper_Redbone @Yankees @Mets Exactly by folk...  \n",
       "2     RT @dril: night time falls. im \"corie latin\" n...  \n",
       "3     Jihadis taunting America &amp; spreading paran...  \n",
       "4     RT @WhatTheFFacts: Actor Charlie Sheen once bo...  \n",
       "5                        I want Oreos!! Who can help me  \n",
       "6             @05proFESSOR I bet he's a Starbucks queer  \n",
       "7     RT @Ih8lightskins__: only a black man can make...  \n",
       "8     @kieffer_jason @zach_smith98 @NathannDevlin so...  \n",
       "9                   Someone shut this beaner up please.  \n",
       "10    @billyeichner Since @TomCruise will be a hoser...  \n",
       "11    #porn,#android,#iphone,#ipad,#sex,#xxx, | #Fis...  \n",
       "12    Think it's okay to take my property and break ...  \n",
       "13    @Buckm00se Joe Cortez is the ultimate faggot t...  \n",
       "14    Oomf a hoe. She know she a hoe, I know she a h...  \n",
       "15                               These bitches is crazy  \n",
       "16    RT @missyantzah: You can do anything you want ...  \n",
       "17    I would like to apologize to anyone I have cal...  \n",
       "18                          Lakers are trash right now.  \n",
       "19    Everyone calls me \"b\" they be like oh wassup b...  \n",
       "20                    @fucktyler fuck you spear chucker  \n",
       "21    @Huntermoore happy cuz I woke up white and not...  \n",
       "22                Fine ass fat bitch... #TwitterLurking  \n",
       "23    bitches ain&#8217;t shit, and they ain&#8217;t...  \n",
       "24    @Kenny__Wright @itsfrankybitch @yoPapi_chulo s...  \n",
       "25    RT @wishfulll: Big booty bitches with... \"@Sta...  \n",
       "26    RT @consprcy_carrot: Blow shit up and get fatt...  \n",
       "27               Can someone get me cheese and crackers  \n",
       "28    &#8220;@__Bino: Looking at nip rings I can't w...  \n",
       "29    RT @AmPowerBlog: @velvethammer Parent in Phoen...  \n",
       "...                                                 ...  \n",
       "4260  Yeah at&amp;t needs to get fucked up with this...  \n",
       "4261  RT @EmilyWCVB: RIGHT NOW: NewsCenter 5 project...  \n",
       "4262  RT @SalamanCode: Proof that thots are retarded...  \n",
       "4263  RT @Chvntre: sometimes I wanna upper cut this ...  \n",
       "4264  When you're grinding with a bitch and she's kn...  \n",
       "4265              #firefighter is a job for white trash  \n",
       "4266  RT @ajade___: everybody tryna fuck the next ni...  \n",
       "4267  People who go to church in Hollywood, CA are a...  \n",
       "4268  The nations know who we are, but we rather be ...  \n",
       "4269  \"Our people\". Now is the time for the Aryan ra...  \n",
       "4270  @jessitron @Bsilverstrim77 ...in fact were I t...  \n",
       "4271             Flaw bitches. Flaw bitches everywhere.  \n",
       "4272  @drboycewatkins1 Coons and monkeys like you di...  \n",
       "4273  @hunterbuch66 @kieffer_jason @sbsylvester yo f...  \n",
       "4274  I forgot how white trash Texarkana was... Well...  \n",
       "4275  thats top off, pop off, im with my dogs like s...  \n",
       "4276                        @LadyVodkax yer dirty pussy  \n",
       "4277                       RT @iDntWearCondoms: 0 hoes.  \n",
       "4278  @BreeOlson @Gingerbeard66 your a nasty nigger ...  \n",
       "4279  @Hunglikerobby_ that was so gay. And I was tan...  \n",
       "4280  @marclamonthill will you mention why being cal...  \n",
       "4281  RT @WolfpackAlan: Oreos: First you twist it, t...  \n",
       "4282                                          Lol bitch  \n",
       "4283  RT @FunSizedYogi: @TheBlackVoice well how else...  \n",
       "4284  @BLUE_yupp finger my throbbing pussy slowly as...  \n",
       "4285       @caykelly16 @MadisonEarhart u guys are fags.  \n",
       "4286  Thinking bout those oysters at the gator bait ...  \n",
       "4287              @longbongchris mk Hun just textith me  \n",
       "4288  International law enforcement operation disrup...  \n",
       "4289  Told my dad to go buy cookies for the graduati...  \n",
       "\n",
       "[4290 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sampling data so we get equal distribution for all classes. used in active learning\n",
    "d0 = dataset[dataset['class'] == 0]\n",
    "d1 = dataset[dataset['class'] == 1].sample(d0.shape[0])\n",
    "d2 = dataset[dataset['class'] == 2].sample(d0.shape[0])\n",
    "\n",
    "#Dl data that is representing same number of all classes. From this we will take n data for starter training as\n",
    "#labeled data, and rest for unlabeled data for active learning\n",
    "Dl = pd.concat([d0,d1,d2])\n",
    "Dl = sklearn.utils.shuffle(Dl)\n",
    "Dl.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_filtered_tweets=[];\n",
    "AL_tweet_tags = [];\n",
    "AL_filtered_tweets_stemmed=[];\n",
    "AL_common_words_prepare=[];\n",
    "\n",
    "for tweet in Dl['tweet']:\n",
    "    tweet = clean_text([\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\".*@.*:\",\"&#*\\w*\",\"@[\\w\\-]+\",\"[^\\w\\s]\"],tweet)\n",
    "    tweet = tweet.lower()\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    common_words = get_common_words(word_tokens)\n",
    "    for word in common_words:\n",
    "        AL_common_words_prepare.append(word)\n",
    "    AL_filtered_tweets.append([word for word in word_tokens if not word in stopwords_list])\n",
    "    AL_filtered_tweets_stemmed.append([ps.stem(word) for word in word_tokens if not word in stopwords_list])\n",
    "    \n",
    "for tweet in AL_filtered_tweets:\n",
    "    AL_tweet_tags.append(nltk.pos_tag(tweet))\n",
    "\n",
    "# Izbacivanje frequent wordsa\n",
    "\n",
    "AL_common_words = get_common_words(AL_common_words_prepare)\n",
    "#for word in filtered_tweets[1:100]:\n",
    "#    print(word)\n",
    "AL_common = []\n",
    "for word in AL_common_words[1:50]:\n",
    "   AL_common.append(word[0][0])\n",
    "\n",
    "AL_filtered_tweets_no_common = [];\n",
    "AL_filtered_tweets_no_common_stemmed = [];\n",
    "for line in AL_filtered_tweets:\n",
    "    AL_filtered_tweets_no_common.append([word for word in line if not word in AL_common])\n",
    "    AL_filtered_tweets_no_common_stemmed.append([ps.stem(word) for word in line if not word in AL_common])\n",
    "#print(\"---------------------------\")\n",
    "#for word in filtered_tweets_no_common[1:100]:\n",
    "#    print(word)\n",
    "\n",
    "AL_ftss=[]\n",
    "for tweet in AL_filtered_tweets_no_common_stemmed:\n",
    "    AL_ftss.append(' '.join(tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL_X = vectorizer.fit_transform(AL_ftss).toarray()\n",
    "AL_Y = Dl['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "Tk_X, Tu_X, Tk_y, _ = train_test_split(AL_X, AL_Y, random_state=42, test_size=0.8)\n",
    "\n",
    "n_labeled_points = math.ceil(len(AL_Y)*0.05)\n",
    "unlabeled_indices = np.arange(len(AL_Y))[n_labeled_points:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 ______________________________________________________________________\n",
      "Label Spreading model: 215 labeled & 4075 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.33      0.40      1353\n",
      "          1       0.38      0.68      0.49      1371\n",
      "          2       0.53      0.29      0.37      1351\n",
      "\n",
      "avg / total       0.47      0.43      0.42      4075\n",
      "\n",
      "Confusion matrix\n",
      "[[449 746 158]\n",
      " [248 931 192]\n",
      " [180 779 392]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mufa/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:52: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 ______________________________________________________________________\n",
      "Label Spreading model: 265 labeled & 4025 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.36      0.42      1332\n",
      "          1       0.39      0.65      0.48      1359\n",
      "          2       0.52      0.32      0.39      1334\n",
      "\n",
      "avg / total       0.47      0.44      0.43      4025\n",
      "\n",
      "Confusion matrix\n",
      "[[475 682 175]\n",
      " [259 883 217]\n",
      " [191 719 424]]\n",
      "Iteration 2 ______________________________________________________________________\n",
      "Label Spreading model: 315 labeled & 3975 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.36      0.42      1309\n",
      "          1       0.39      0.66      0.49      1343\n",
      "          2       0.53      0.31      0.39      1323\n",
      "\n",
      "avg / total       0.48      0.44      0.43      3975\n",
      "\n",
      "Confusion matrix\n",
      "[[468 680 161]\n",
      " [252 886 205]\n",
      " [189 724 410]]\n",
      "Iteration 3 ______________________________________________________________________\n",
      "Label Spreading model: 365 labeled & 3925 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.40      0.46      1287\n",
      "          1       0.39      0.66      0.49      1322\n",
      "          2       0.53      0.30      0.38      1316\n",
      "\n",
      "avg / total       0.48      0.45      0.44      3925\n",
      "\n",
      "Confusion matrix\n",
      "[[518 614 155]\n",
      " [263 866 193]\n",
      " [203 723 390]]\n",
      "Iteration 4 ______________________________________________________________________\n",
      "Label Spreading model: 415 labeled & 3875 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.42      0.47      1272\n",
      "          1       0.40      0.64      0.49      1302\n",
      "          2       0.53      0.30      0.39      1301\n",
      "\n",
      "avg / total       0.49      0.46      0.45      3875\n",
      "\n",
      "Confusion matrix\n",
      "[[540 575 157]\n",
      " [271 837 194]\n",
      " [203 703 395]]\n",
      "Iteration 5 ______________________________________________________________________\n",
      "Label Spreading model: 465 labeled & 3825 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.43      0.46      1241\n",
      "          1       0.40      0.62      0.49      1290\n",
      "          2       0.54      0.32      0.40      1294\n",
      "\n",
      "avg / total       0.48      0.46      0.45      3825\n",
      "\n",
      "Confusion matrix\n",
      "[[529 559 153]\n",
      " [292 804 194]\n",
      " [231 648 415]]\n",
      "Iteration 6 ______________________________________________________________________\n",
      "Label Spreading model: 515 labeled & 3775 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.47      0.48      1222\n",
      "          1       0.40      0.59      0.48      1278\n",
      "          2       0.56      0.32      0.41      1275\n",
      "\n",
      "avg / total       0.48      0.46      0.46      3775\n",
      "\n",
      "Confusion matrix\n",
      "[[569 513 140]\n",
      " [328 759 191]\n",
      " [247 615 413]]\n",
      "Iteration 7 ______________________________________________________________________\n",
      "Label Spreading model: 565 labeled & 3725 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.45      0.47      1217\n",
      "          1       0.41      0.59      0.48      1258\n",
      "          2       0.56      0.36      0.44      1250\n",
      "\n",
      "avg / total       0.49      0.46      0.46      3725\n",
      "\n",
      "Confusion matrix\n",
      "[[548 515 154]\n",
      " [321 737 200]\n",
      " [241 563 446]]\n",
      "Iteration 8 ______________________________________________________________________\n",
      "Label Spreading model: 615 labeled & 3675 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.44      0.46      1209\n",
      "          1       0.41      0.59      0.48      1243\n",
      "          2       0.56      0.37      0.45      1223\n",
      "\n",
      "avg / total       0.49      0.47      0.46      3675\n",
      "\n",
      "Confusion matrix\n",
      "[[529 521 159]\n",
      " [313 733 197]\n",
      " [233 535 455]]\n",
      "Iteration 9 ______________________________________________________________________\n",
      "Label Spreading model: 665 labeled & 3625 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.42      0.46      1202\n",
      "          1       0.40      0.59      0.48      1219\n",
      "          2       0.55      0.38      0.45      1204\n",
      "\n",
      "avg / total       0.48      0.46      0.46      3625\n",
      "\n",
      "Confusion matrix\n",
      "[[506 528 168]\n",
      " [291 716 212]\n",
      " [208 536 460]]\n",
      "Iteration 10 ______________________________________________________________________\n",
      "Label Spreading model: 715 labeled & 3575 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.42      0.46      1190\n",
      "          1       0.41      0.58      0.48      1201\n",
      "          2       0.55      0.42      0.47      1184\n",
      "\n",
      "avg / total       0.49      0.47      0.47      3575\n",
      "\n",
      "Confusion matrix\n",
      "[[499 505 186]\n",
      " [286 699 216]\n",
      " [199 493 492]]\n",
      "Iteration 11 ______________________________________________________________________\n",
      "Label Spreading model: 765 labeled & 3525 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.40      0.45      1183\n",
      "          1       0.41      0.59      0.48      1178\n",
      "          2       0.56      0.43      0.48      1164\n",
      "\n",
      "avg / total       0.49      0.47      0.47      3525\n",
      "\n",
      "Confusion matrix\n",
      "[[478 520 185]\n",
      " [267 697 214]\n",
      " [175 491 498]]\n",
      "Iteration 12 ______________________________________________________________________\n",
      "Label Spreading model: 815 labeled & 3475 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.41      0.46      1161\n",
      "          1       0.41      0.59      0.48      1162\n",
      "          2       0.56      0.44      0.49      1152\n",
      "\n",
      "avg / total       0.50      0.48      0.48      3475\n",
      "\n",
      "Confusion matrix\n",
      "[[474 508 179]\n",
      " [262 681 219]\n",
      " [168 481 503]]\n",
      "Iteration 13 ______________________________________________________________________\n",
      "Label Spreading model: 865 labeled & 3425 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.41      0.46      1147\n",
      "          1       0.41      0.58      0.48      1146\n",
      "          2       0.56      0.44      0.49      1132\n",
      "\n",
      "avg / total       0.49      0.48      0.48      3425\n",
      "\n",
      "Confusion matrix\n",
      "[[470 501 176]\n",
      " [270 666 210]\n",
      " [175 462 495]]\n",
      "Iteration 14 ______________________________________________________________________\n",
      "Label Spreading model: 915 labeled & 3375 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.40      0.45      1138\n",
      "          1       0.41      0.56      0.47      1123\n",
      "          2       0.55      0.46      0.50      1114\n",
      "\n",
      "avg / total       0.49      0.48      0.48      3375\n",
      "\n",
      "Confusion matrix\n",
      "[[455 493 190]\n",
      " [253 631 239]\n",
      " [166 430 518]]\n",
      "Iteration 15 ______________________________________________________________________\n",
      "Label Spreading model: 965 labeled & 3325 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.40      0.45      1124\n",
      "          1       0.40      0.58      0.48      1098\n",
      "          2       0.55      0.45      0.49      1103\n",
      "\n",
      "avg / total       0.49      0.47      0.47      3325\n",
      "\n",
      "Confusion matrix\n",
      "[[449 491 184]\n",
      " [246 636 216]\n",
      " [164 446 493]]\n",
      "Iteration 16 ______________________________________________________________________\n",
      "Label Spreading model: 1015 labeled & 3275 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.40      0.46      1107\n",
      "          1       0.41      0.58      0.48      1081\n",
      "          2       0.55      0.45      0.49      1087\n",
      "\n",
      "avg / total       0.50      0.48      0.48      3275\n",
      "\n",
      "Confusion matrix\n",
      "[[446 478 183]\n",
      " [240 630 211]\n",
      " [161 440 486]]\n",
      "Iteration 17 ______________________________________________________________________\n",
      "Label Spreading model: 1065 labeled & 3225 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.41      0.46      1096\n",
      "          1       0.41      0.58      0.48      1058\n",
      "          2       0.55      0.45      0.49      1071\n",
      "\n",
      "avg / total       0.49      0.48      0.48      3225\n",
      "\n",
      "Confusion matrix\n",
      "[[444 464 188]\n",
      " [238 610 210]\n",
      " [160 431 480]]\n",
      "Iteration 18 ______________________________________________________________________\n",
      "Label Spreading model: 1115 labeled & 3175 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.40      0.46      1090\n",
      "          1       0.41      0.59      0.48      1033\n",
      "          2       0.56      0.47      0.51      1052\n",
      "\n",
      "avg / total       0.50      0.48      0.48      3175\n",
      "\n",
      "Confusion matrix\n",
      "[[437 469 184]\n",
      " [224 606 203]\n",
      " [156 406 490]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19 ______________________________________________________________________\n",
      "Label Spreading model: 1165 labeled & 3125 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.40      0.46      1075\n",
      "          1       0.40      0.58      0.48      1015\n",
      "          2       0.55      0.46      0.50      1035\n",
      "\n",
      "avg / total       0.50      0.48      0.48      3125\n",
      "\n",
      "Confusion matrix\n",
      "[[429 464 182]\n",
      " [221 591 203]\n",
      " [153 409 473]]\n",
      "Iteration 20 ______________________________________________________________________\n",
      "Label Spreading model: 1215 labeled & 3075 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.40      0.45      1061\n",
      "          1       0.41      0.57      0.48      1000\n",
      "          2       0.54      0.48      0.51      1014\n",
      "\n",
      "avg / total       0.50      0.48      0.48      3075\n",
      "\n",
      "Confusion matrix\n",
      "[[422 444 195]\n",
      " [220 569 211]\n",
      " [152 379 483]]\n",
      "Iteration 21 ______________________________________________________________________\n",
      "Label Spreading model: 1265 labeled & 3025 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.42      0.47      1051\n",
      "          1       0.41      0.55      0.47       988\n",
      "          2       0.55      0.49      0.52       986\n",
      "\n",
      "avg / total       0.50      0.49      0.49      3025\n",
      "\n",
      "Confusion matrix\n",
      "[[442 426 183]\n",
      " [234 544 210]\n",
      " [156 346 484]]\n",
      "Iteration 22 ______________________________________________________________________\n",
      "Label Spreading model: 1315 labeled & 2975 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.42      0.47      1040\n",
      "          1       0.42      0.55      0.48       967\n",
      "          2       0.55      0.51      0.53       968\n",
      "\n",
      "avg / total       0.51      0.49      0.49      2975\n",
      "\n",
      "Confusion matrix\n",
      "[[438 408 194]\n",
      " [228 531 208]\n",
      " [145 326 497]]\n",
      "Iteration 23 ______________________________________________________________________\n",
      "Label Spreading model: 1365 labeled & 2925 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.41      0.47      1025\n",
      "          1       0.42      0.56      0.48       940\n",
      "          2       0.56      0.51      0.53       960\n",
      "\n",
      "avg / total       0.51      0.49      0.49      2925\n",
      "\n",
      "Confusion matrix\n",
      "[[421 410 194]\n",
      " [214 526 200]\n",
      " [140 327 493]]\n",
      "Iteration 24 ______________________________________________________________________\n",
      "Label Spreading model: 1415 labeled & 2875 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.41      0.47      1002\n",
      "          1       0.42      0.56      0.48       920\n",
      "          2       0.56      0.52      0.54       953\n",
      "\n",
      "avg / total       0.51      0.49      0.49      2875\n",
      "\n",
      "Confusion matrix\n",
      "[[411 400 191]\n",
      " [203 518 199]\n",
      " [139 322 492]]\n",
      "Iteration 25 ______________________________________________________________________\n",
      "Label Spreading model: 1465 labeled & 2825 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.42      0.47       983\n",
      "          1       0.42      0.55      0.47       901\n",
      "          2       0.55      0.51      0.53       941\n",
      "\n",
      "avg / total       0.50      0.49      0.49      2825\n",
      "\n",
      "Confusion matrix\n",
      "[[409 380 194]\n",
      " [210 498 193]\n",
      " [141 319 481]]\n",
      "Iteration 26 ______________________________________________________________________\n",
      "Label Spreading model: 1515 labeled & 2775 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.41      0.46       971\n",
      "          1       0.41      0.55      0.47       882\n",
      "          2       0.55      0.52      0.53       922\n",
      "\n",
      "avg / total       0.50      0.49      0.49      2775\n",
      "\n",
      "Confusion matrix\n",
      "[[396 379 196]\n",
      " [211 486 185]\n",
      " [135 312 475]]\n",
      "Iteration 27 ______________________________________________________________________\n",
      "Label Spreading model: 1565 labeled & 2725 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.40      0.46       960\n",
      "          1       0.42      0.55      0.47       867\n",
      "          2       0.55      0.53      0.54       898\n",
      "\n",
      "avg / total       0.50      0.49      0.49      2725\n",
      "\n",
      "Confusion matrix\n",
      "[[385 370 205]\n",
      " [206 473 188]\n",
      " [130 295 473]]\n",
      "Iteration 28 ______________________________________________________________________\n",
      "Label Spreading model: 1615 labeled & 2675 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.40      0.46       944\n",
      "          1       0.41      0.54      0.47       847\n",
      "          2       0.55      0.54      0.55       884\n",
      "\n",
      "avg / total       0.50      0.49      0.49      2675\n",
      "\n",
      "Confusion matrix\n",
      "[[380 366 198]\n",
      " [205 457 185]\n",
      " [123 285 476]]\n",
      "Iteration 29 ______________________________________________________________________\n",
      "Label Spreading model: 1665 labeled & 2625 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.40      0.46       929\n",
      "          1       0.41      0.54      0.47       831\n",
      "          2       0.55      0.55      0.55       865\n",
      "\n",
      "avg / total       0.50      0.49      0.49      2625\n",
      "\n",
      "Confusion matrix\n",
      "[[369 359 201]\n",
      " [199 446 186]\n",
      " [117 274 474]]\n",
      "Iteration 30 ______________________________________________________________________\n",
      "Label Spreading model: 1715 labeled & 2575 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.39      0.46       913\n",
      "          1       0.41      0.54      0.47       810\n",
      "          2       0.55      0.55      0.55       852\n",
      "\n",
      "avg / total       0.50      0.49      0.49      2575\n",
      "\n",
      "Confusion matrix\n",
      "[[358 360 195]\n",
      " [189 439 182]\n",
      " [112 273 467]]\n",
      "Iteration 31 ______________________________________________________________________\n",
      "Label Spreading model: 1765 labeled & 2525 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.39      0.46       892\n",
      "          1       0.41      0.55      0.47       790\n",
      "          2       0.55      0.55      0.55       843\n",
      "\n",
      "avg / total       0.51      0.49      0.49      2525\n",
      "\n",
      "Confusion matrix\n",
      "[[350 350 192]\n",
      " [176 436 178]\n",
      " [110 272 461]]\n",
      "Iteration 32 ______________________________________________________________________\n",
      "Label Spreading model: 1815 labeled & 2475 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.39      0.46       877\n",
      "          1       0.41      0.55      0.47       776\n",
      "          2       0.55      0.55      0.55       822\n",
      "\n",
      "avg / total       0.51      0.49      0.49      2475\n",
      "\n",
      "Confusion matrix\n",
      "[[344 347 186]\n",
      " [175 423 178]\n",
      " [105 264 453]]\n",
      "Iteration 33 ______________________________________________________________________\n",
      "Label Spreading model: 1865 labeled & 2425 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.39      0.46       861\n",
      "          1       0.41      0.54      0.47       761\n",
      "          2       0.56      0.57      0.56       803\n",
      "\n",
      "avg / total       0.51      0.50      0.50      2425\n",
      "\n",
      "Confusion matrix\n",
      "[[337 341 183]\n",
      " [173 412 176]\n",
      " [ 97 252 454]]\n",
      "Iteration 34 ______________________________________________________________________\n",
      "Label Spreading model: 1915 labeled & 2375 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.40      0.46       838\n",
      "          1       0.41      0.54      0.47       739\n",
      "          2       0.56      0.56      0.56       798\n",
      "\n",
      "avg / total       0.51      0.50      0.50      2375\n",
      "\n",
      "Confusion matrix\n",
      "[[332 330 176]\n",
      " [167 400 172]\n",
      " [100 250 448]]\n",
      "Iteration 35 ______________________________________________________________________\n",
      "Label Spreading model: 1965 labeled & 2325 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.40      0.46       819\n",
      "          1       0.41      0.54      0.47       725\n",
      "          2       0.56      0.56      0.56       781\n",
      "\n",
      "avg / total       0.51      0.50      0.50      2325\n",
      "\n",
      "Confusion matrix\n",
      "[[326 317 176]\n",
      " [166 391 168]\n",
      " [101 241 439]]\n",
      "Iteration 36 ______________________________________________________________________\n",
      "Label Spreading model: 2015 labeled & 2275 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.41      0.47       807\n",
      "          1       0.42      0.54      0.47       711\n",
      "          2       0.56      0.57      0.57       757\n",
      "\n",
      "avg / total       0.51      0.50      0.50      2275\n",
      "\n",
      "Confusion matrix\n",
      "[[328 306 173]\n",
      " [164 381 166]\n",
      " [ 97 226 434]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 37 ______________________________________________________________________\n",
      "Label Spreading model: 2065 labeled & 2225 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.41      0.47       788\n",
      "          1       0.42      0.54      0.47       700\n",
      "          2       0.57      0.58      0.57       737\n",
      "\n",
      "avg / total       0.52      0.51      0.51      2225\n",
      "\n",
      "Confusion matrix\n",
      "[[323 304 161]\n",
      " [167 375 158]\n",
      " [ 93 218 426]]\n",
      "Iteration 38 ______________________________________________________________________\n",
      "Label Spreading model: 2115 labeled & 2175 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.41      0.47       765\n",
      "          1       0.42      0.53      0.46       685\n",
      "          2       0.57      0.58      0.58       725\n",
      "\n",
      "avg / total       0.51      0.50      0.50      2175\n",
      "\n",
      "Confusion matrix\n",
      "[[316 293 156]\n",
      " [170 360 155]\n",
      " [ 93 213 419]]\n",
      "Iteration 39 ______________________________________________________________________\n",
      "Label Spreading model: 2165 labeled & 2125 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.41      0.47       750\n",
      "          1       0.42      0.54      0.47       664\n",
      "          2       0.58      0.58      0.58       711\n",
      "\n",
      "avg / total       0.52      0.51      0.51      2125\n",
      "\n",
      "Confusion matrix\n",
      "[[311 289 150]\n",
      " [164 356 144]\n",
      " [ 90 211 410]]\n",
      "Iteration 40 ______________________________________________________________________\n",
      "Label Spreading model: 2215 labeled & 2075 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.42      0.47       725\n",
      "          1       0.42      0.53      0.47       650\n",
      "          2       0.58      0.58      0.58       700\n",
      "\n",
      "avg / total       0.52      0.51      0.51      2075\n",
      "\n",
      "Confusion matrix\n",
      "[[301 276 148]\n",
      " [161 344 145]\n",
      " [ 91 202 407]]\n",
      "Iteration 41 ______________________________________________________________________\n",
      "Label Spreading model: 2265 labeled & 2025 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.42      0.47       701\n",
      "          1       0.42      0.52      0.47       635\n",
      "          2       0.58      0.58      0.58       689\n",
      "\n",
      "avg / total       0.52      0.51      0.51      2025\n",
      "\n",
      "Confusion matrix\n",
      "[[293 263 145]\n",
      " [160 333 142]\n",
      " [ 88 199 402]]\n",
      "Iteration 42 ______________________________________________________________________\n",
      "Label Spreading model: 2315 labeled & 1975 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.42      0.47       685\n",
      "          1       0.42      0.53      0.46       611\n",
      "          2       0.59      0.58      0.59       679\n",
      "\n",
      "avg / total       0.52      0.51      0.51      1975\n",
      "\n",
      "Confusion matrix\n",
      "[[288 256 141]\n",
      " [155 321 135]\n",
      " [ 87 195 397]]\n",
      "Iteration 43 ______________________________________________________________________\n",
      "Label Spreading model: 2365 labeled & 1925 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.42      0.48       665\n",
      "          1       0.42      0.52      0.46       598\n",
      "          2       0.59      0.59      0.59       662\n",
      "\n",
      "avg / total       0.52      0.51      0.51      1925\n",
      "\n",
      "Confusion matrix\n",
      "[[282 248 135]\n",
      " [154 313 131]\n",
      " [ 83 189 390]]\n",
      "Iteration 44 ______________________________________________________________________\n",
      "Label Spreading model: 2415 labeled & 1875 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.43      0.48       647\n",
      "          1       0.42      0.53      0.47       576\n",
      "          2       0.61      0.59      0.60       652\n",
      "\n",
      "avg / total       0.53      0.52      0.52      1875\n",
      "\n",
      "Confusion matrix\n",
      "[[276 242 129]\n",
      " [147 306 123]\n",
      " [ 81 185 386]]\n",
      "Iteration 45 ______________________________________________________________________\n",
      "Label Spreading model: 2465 labeled & 1825 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.43      0.48       632\n",
      "          1       0.42      0.54      0.47       561\n",
      "          2       0.61      0.59      0.60       632\n",
      "\n",
      "avg / total       0.53      0.52      0.52      1825\n",
      "\n",
      "Confusion matrix\n",
      "[[269 238 125]\n",
      " [146 302 113]\n",
      " [ 76 180 376]]\n",
      "Iteration 46 ______________________________________________________________________\n",
      "Label Spreading model: 2515 labeled & 1775 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.43      0.48       609\n",
      "          1       0.42      0.54      0.47       543\n",
      "          2       0.62      0.59      0.61       623\n",
      "\n",
      "avg / total       0.53      0.52      0.52      1775\n",
      "\n",
      "Confusion matrix\n",
      "[[264 229 116]\n",
      " [144 294 105]\n",
      " [ 77 179 367]]\n",
      "Iteration 47 ______________________________________________________________________\n",
      "Label Spreading model: 2565 labeled & 1725 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.44      0.49       593\n",
      "          1       0.42      0.54      0.47       529\n",
      "          2       0.63      0.59      0.61       603\n",
      "\n",
      "avg / total       0.54      0.52      0.53      1725\n",
      "\n",
      "Confusion matrix\n",
      "[[259 223 111]\n",
      " [138 288 103]\n",
      " [ 72 174 357]]\n",
      "Iteration 48 ______________________________________________________________________\n",
      "Label Spreading model: 2615 labeled & 1675 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.41      0.46       557\n",
      "          1       0.42      0.54      0.47       519\n",
      "          2       0.63      0.59      0.61       599\n",
      "\n",
      "avg / total       0.53      0.52      0.52      1675\n",
      "\n",
      "Confusion matrix\n",
      "[[230 219 108]\n",
      " [138 282  99]\n",
      " [ 71 172 356]]\n",
      "Iteration 49 ______________________________________________________________________\n",
      "Label Spreading model: 2665 labeled & 1625 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.41      0.46       534\n",
      "          1       0.42      0.56      0.48       503\n",
      "          2       0.65      0.59      0.61       588\n",
      "\n",
      "avg / total       0.53      0.52      0.52      1625\n",
      "\n",
      "Confusion matrix\n",
      "[[219 214 101]\n",
      " [134 281  88]\n",
      " [ 70 173 345]]\n",
      "Iteration 50 ______________________________________________________________________\n",
      "Label Spreading model: 2715 labeled & 1575 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.41      0.46       515\n",
      "          1       0.43      0.57      0.49       485\n",
      "          2       0.65      0.60      0.63       575\n",
      "\n",
      "avg / total       0.54      0.53      0.53      1575\n",
      "\n",
      "Confusion matrix\n",
      "[[212 203 100]\n",
      " [124 276  85]\n",
      " [ 67 161 347]]\n",
      "Iteration 51 ______________________________________________________________________\n",
      "Label Spreading model: 2765 labeled & 1525 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.42      0.47       498\n",
      "          1       0.43      0.58      0.50       467\n",
      "          2       0.66      0.61      0.63       560\n",
      "\n",
      "avg / total       0.55      0.54      0.54      1525\n",
      "\n",
      "Confusion matrix\n",
      "[[210 194  94]\n",
      " [116 269  82]\n",
      " [ 64 156 340]]\n",
      "Iteration 52 ______________________________________________________________________\n",
      "Label Spreading model: 2815 labeled & 1475 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.42      0.47       479\n",
      "          1       0.44      0.57      0.50       456\n",
      "          2       0.65      0.60      0.63       540\n",
      "\n",
      "avg / total       0.55      0.53      0.53      1475\n",
      "\n",
      "Confusion matrix\n",
      "[[199 186  94]\n",
      " [113 262  81]\n",
      " [ 63 151 326]]\n",
      "Iteration 53 ______________________________________________________________________\n",
      "Label Spreading model: 2865 labeled & 1425 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.42      0.46       465\n",
      "          1       0.44      0.57      0.50       440\n",
      "          2       0.65      0.60      0.62       520\n",
      "\n",
      "avg / total       0.54      0.53      0.53      1425\n",
      "\n",
      "Confusion matrix\n",
      "[[193 179  93]\n",
      " [110 251  79]\n",
      " [ 63 143 314]]\n",
      "Iteration 54 ______________________________________________________________________\n",
      "Label Spreading model: 2915 labeled & 1375 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.42      0.47       445\n",
      "          1       0.44      0.58      0.50       423\n",
      "          2       0.66      0.61      0.64       507\n",
      "\n",
      "avg / total       0.55      0.54      0.54      1375\n",
      "\n",
      "Confusion matrix\n",
      "[[185 176  84]\n",
      " [103 247  73]\n",
      " [ 62 134 311]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 55 ______________________________________________________________________\n",
      "Label Spreading model: 2965 labeled & 1325 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.41      0.46       424\n",
      "          1       0.44      0.60      0.51       402\n",
      "          2       0.67      0.62      0.64       499\n",
      "\n",
      "avg / total       0.56      0.54      0.54      1325\n",
      "\n",
      "Confusion matrix\n",
      "[[172 170  82]\n",
      " [ 93 241  68]\n",
      " [ 60 131 308]]\n",
      "Iteration 56 ______________________________________________________________________\n",
      "Label Spreading model: 3015 labeled & 1275 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.41      0.46       409\n",
      "          1       0.43      0.59      0.50       379\n",
      "          2       0.67      0.62      0.65       487\n",
      "\n",
      "avg / total       0.56      0.54      0.54      1275\n",
      "\n",
      "Confusion matrix\n",
      "[[167 163  79]\n",
      " [ 90 223  66]\n",
      " [ 59 127 301]]\n",
      "Iteration 57 ______________________________________________________________________\n",
      "Label Spreading model: 3065 labeled & 1225 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.41      0.46       395\n",
      "          1       0.43      0.58      0.49       357\n",
      "          2       0.68      0.63      0.65       473\n",
      "\n",
      "avg / total       0.56      0.54      0.54      1225\n",
      "\n",
      "Confusion matrix\n",
      "[[162 154  79]\n",
      " [ 87 207  63]\n",
      " [ 56 121 296]]\n",
      "Iteration 58 ______________________________________________________________________\n",
      "Label Spreading model: 3115 labeled & 1175 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.41      0.46       376\n",
      "          1       0.43      0.57      0.49       348\n",
      "          2       0.67      0.63      0.65       451\n",
      "\n",
      "avg / total       0.55      0.54      0.54      1175\n",
      "\n",
      "Confusion matrix\n",
      "[[154 145  77]\n",
      " [ 87 199  62]\n",
      " [ 52 115 284]]\n",
      "Iteration 59 ______________________________________________________________________\n",
      "Label Spreading model: 3165 labeled & 1125 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.42      0.48       361\n",
      "          1       0.44      0.58      0.50       328\n",
      "          2       0.67      0.63      0.65       436\n",
      "\n",
      "avg / total       0.56      0.55      0.55      1125\n",
      "\n",
      "Confusion matrix\n",
      "[[153 133  75]\n",
      " [ 81 189  58]\n",
      " [ 49 111 276]]\n",
      "Iteration 60 ______________________________________________________________________\n",
      "Label Spreading model: 3215 labeled & 1075 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.44      0.49       345\n",
      "          1       0.44      0.58      0.50       314\n",
      "          2       0.68      0.64      0.66       416\n",
      "\n",
      "avg / total       0.57      0.56      0.56      1075\n",
      "\n",
      "Confusion matrix\n",
      "[[152 123  70]\n",
      " [ 75 182  57]\n",
      " [ 43 106 267]]\n",
      "Iteration 61 ______________________________________________________________________\n",
      "Label Spreading model: 3265 labeled & 1025 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.44      0.49       326\n",
      "          1       0.44      0.57      0.50       301\n",
      "          2       0.68      0.64      0.66       398\n",
      "\n",
      "avg / total       0.57      0.56      0.56      1025\n",
      "\n",
      "Confusion matrix\n",
      "[[144 116  66]\n",
      " [ 75 173  53]\n",
      " [ 40 103 255]]\n",
      "Iteration 62 ______________________________________________________________________\n",
      "Label Spreading model: 3315 labeled & 975 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.46      0.50       305\n",
      "          1       0.45      0.58      0.50       287\n",
      "          2       0.70      0.64      0.67       383\n",
      "\n",
      "avg / total       0.58      0.57      0.57       975\n",
      "\n",
      "Confusion matrix\n",
      "[[139 108  58]\n",
      " [ 75 166  46]\n",
      " [ 39  98 246]]\n",
      "Iteration 63 ______________________________________________________________________\n",
      "Label Spreading model: 3365 labeled & 925 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.47      0.51       290\n",
      "          1       0.44      0.58      0.50       268\n",
      "          2       0.72      0.64      0.68       367\n",
      "\n",
      "avg / total       0.59      0.57      0.57       925\n",
      "\n",
      "Confusion matrix\n",
      "[[136 103  51]\n",
      " [ 70 155  43]\n",
      " [ 39  92 236]]\n",
      "Iteration 64 ______________________________________________________________________\n",
      "Label Spreading model: 3415 labeled & 875 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.46      0.50       274\n",
      "          1       0.44      0.59      0.51       248\n",
      "          2       0.72      0.65      0.68       353\n",
      "\n",
      "avg / total       0.59      0.57      0.58       875\n",
      "\n",
      "Confusion matrix\n",
      "[[125  99  50]\n",
      " [ 62 147  39]\n",
      " [ 36  87 230]]\n",
      "Iteration 65 ______________________________________________________________________\n",
      "Label Spreading model: 3465 labeled & 825 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.46      0.52       263\n",
      "          1       0.44      0.59      0.50       233\n",
      "          2       0.73      0.67      0.70       329\n",
      "\n",
      "avg / total       0.60      0.58      0.59       825\n",
      "\n",
      "Confusion matrix\n",
      "[[122  95  46]\n",
      " [ 59 137  37]\n",
      " [ 29  78 222]]\n",
      "Iteration 66 ______________________________________________________________________\n",
      "Label Spreading model: 3515 labeled & 775 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.46      0.51       245\n",
      "          1       0.44      0.59      0.51       218\n",
      "          2       0.73      0.68      0.70       312\n",
      "\n",
      "avg / total       0.60      0.58      0.59       775\n",
      "\n",
      "Confusion matrix\n",
      "[[113  89  43]\n",
      " [ 55 129  34]\n",
      " [ 28  73 211]]\n",
      "Iteration 67 ______________________________________________________________________\n",
      "Label Spreading model: 3565 labeled & 725 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.47      0.52       226\n",
      "          1       0.45      0.60      0.51       203\n",
      "          2       0.75      0.69      0.72       296\n",
      "\n",
      "avg / total       0.61      0.59      0.60       725\n",
      "\n",
      "Confusion matrix\n",
      "[[107  80  39]\n",
      " [ 53 121  29]\n",
      " [ 26  67 203]]\n",
      "Iteration 68 ______________________________________________________________________\n",
      "Label Spreading model: 3615 labeled & 675 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.48      0.53       211\n",
      "          1       0.46      0.62      0.53       185\n",
      "          2       0.77      0.69      0.73       279\n",
      "\n",
      "avg / total       0.63      0.61      0.61       675\n",
      "\n",
      "Confusion matrix\n",
      "[[101  74  36]\n",
      " [ 48 115  22]\n",
      " [ 23  63 193]]\n",
      "Iteration 69 ______________________________________________________________________\n",
      "Label Spreading model: 3665 labeled & 625 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.46      0.50       189\n",
      "          1       0.45      0.61      0.52       173\n",
      "          2       0.77      0.70      0.73       263\n",
      "\n",
      "avg / total       0.62      0.60      0.60       625\n",
      "\n",
      "Confusion matrix\n",
      "[[ 86  69  34]\n",
      " [ 46 105  22]\n",
      " [ 21  59 183]]\n",
      "Iteration 70 ______________________________________________________________________\n",
      "Label Spreading model: 3715 labeled & 575 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.45      0.49       167\n",
      "          1       0.46      0.60      0.52       159\n",
      "          2       0.77      0.70      0.73       249\n",
      "\n",
      "avg / total       0.62      0.60      0.60       575\n",
      "\n",
      "Confusion matrix\n",
      "[[ 75  60  32]\n",
      " [ 42  96  21]\n",
      " [ 21  54 174]]\n",
      "Iteration 71 ______________________________________________________________________\n",
      "Label Spreading model: 3765 labeled & 525 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.43      0.48       152\n",
      "          1       0.48      0.60      0.53       146\n",
      "          2       0.77      0.74      0.75       227\n",
      "\n",
      "avg / total       0.62      0.61      0.61       525\n",
      "\n",
      "Confusion matrix\n",
      "[[ 66  56  30]\n",
      " [ 39  88  19]\n",
      " [ 20  40 167]]\n",
      "Iteration 72 ______________________________________________________________________\n",
      "Label Spreading model: 3815 labeled & 475 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.52      0.43      0.47       135\n",
      "          1       0.49      0.62      0.55       133\n",
      "          2       0.78      0.74      0.76       207\n",
      "\n",
      "avg / total       0.63      0.62      0.62       475\n",
      "\n",
      "Confusion matrix\n",
      "[[ 58  50  27]\n",
      " [ 35  82  16]\n",
      " [ 18  35 154]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 73 ______________________________________________________________________\n",
      "Label Spreading model: 3865 labeled & 425 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.42      0.47       120\n",
      "          1       0.50      0.61      0.55       115\n",
      "          2       0.78      0.77      0.77       190\n",
      "\n",
      "avg / total       0.63      0.63      0.63       425\n",
      "\n",
      "Confusion matrix\n",
      "[[ 51  43  26]\n",
      " [ 29  70  16]\n",
      " [ 16  28 146]]\n",
      "Iteration 74 ______________________________________________________________________\n",
      "Label Spreading model: 3915 labeled & 375 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.46      0.51       102\n",
      "          1       0.51      0.61      0.56       101\n",
      "          2       0.80      0.79      0.80       172\n",
      "\n",
      "avg / total       0.66      0.65      0.65       375\n",
      "\n",
      "Confusion matrix\n",
      "[[ 47  36  19]\n",
      " [ 24  62  15]\n",
      " [ 13  23 136]]\n",
      "Iteration 75 ______________________________________________________________________\n",
      "Label Spreading model: 3965 labeled & 325 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.51      0.56        91\n",
      "          1       0.53      0.65      0.58        80\n",
      "          2       0.82      0.82      0.82       154\n",
      "\n",
      "avg / total       0.69      0.69      0.69       325\n",
      "\n",
      "Confusion matrix\n",
      "[[ 46  29  16]\n",
      " [ 17  52  11]\n",
      " [ 11  17 126]]\n",
      "Iteration 76 ______________________________________________________________________\n",
      "Label Spreading model: 4015 labeled & 275 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.61      0.52      0.56        71\n",
      "          1       0.54      0.62      0.58        66\n",
      "          2       0.84      0.84      0.84       138\n",
      "\n",
      "avg / total       0.71      0.71      0.71       275\n",
      "\n",
      "Confusion matrix\n",
      "[[ 37  21  13]\n",
      " [ 16  41   9]\n",
      " [  8  14 116]]\n",
      "Iteration 77 ______________________________________________________________________\n",
      "Label Spreading model: 4065 labeled & 225 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.58      0.61        60\n",
      "          1       0.53      0.54      0.54        48\n",
      "          2       0.84      0.88      0.86       117\n",
      "\n",
      "avg / total       0.73      0.73      0.73       225\n",
      "\n",
      "Confusion matrix\n",
      "[[ 35  14  11]\n",
      " [ 14  26   8]\n",
      " [  5   9 103]]\n",
      "Iteration 78 ______________________________________________________________________\n",
      "Label Spreading model: 4115 labeled & 175 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.60      0.61        45\n",
      "          1       0.53      0.52      0.52        33\n",
      "          2       0.87      0.90      0.88        97\n",
      "\n",
      "avg / total       0.74      0.75      0.75       175\n",
      "\n",
      "Confusion matrix\n",
      "[[27  9  9]\n",
      " [12 17  4]\n",
      " [ 4  6 87]]\n",
      "Iteration 79 ______________________________________________________________________\n",
      "Label Spreading model: 4165 labeled & 125 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.70      0.68        33\n",
      "          1       0.44      0.55      0.49        20\n",
      "          2       0.97      0.88      0.92        72\n",
      "\n",
      "avg / total       0.80      0.78      0.79       125\n",
      "\n",
      "Confusion matrix\n",
      "[[23  9  1]\n",
      " [ 8 11  1]\n",
      " [ 4  5 63]]\n",
      "Iteration 80 ______________________________________________________________________\n",
      "Label Spreading model: 4215 labeled & 75 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.93      0.76        14\n",
      "          1       1.00      0.50      0.67         8\n",
      "          2       0.98      0.94      0.96        53\n",
      "\n",
      "avg / total       0.92      0.89      0.89        75\n",
      "\n",
      "Confusion matrix\n",
      "[[13  0  1]\n",
      " [ 4  4  0]\n",
      " [ 3  0 50]]\n",
      "Iteration 81 ______________________________________________________________________\n",
      "Label Spreading model: 4265 labeled & 25 unlabeled (4290 total)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       1.00      1.00      1.00         1\n",
      "          2       0.96      0.96      0.96        23\n",
      "\n",
      "avg / total       0.92      0.92      0.92        25\n",
      "\n",
      "Confusion matrix\n",
      "[[ 0  0  1]\n",
      " [ 0  1  0]\n",
      " [ 1  0 22]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb789a754e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.semi_supervised import label_propagation\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "max_iterations = 100\n",
    "f = plt.figure()\n",
    "for i in range(max_iterations):\n",
    "    if len(Tu) == 0 :\n",
    "        print(\"No unlabeled data to label.\")\n",
    "        break\n",
    "    al_model = label_propagation.LabelSpreading(gamma=0.25,max_iter=50)\n",
    "    y_train = np.copy(AL_Y)\n",
    "    y_train[unlabeled_indices] = -1\n",
    "    al_model.fit(AL_X,y_train)\n",
    "    predicted_labels = al_model.transduction_[unlabeled_indices]\n",
    "    true_labels = [AL_Y[i] for i in unlabeled_indices]\n",
    "    if set(al_model.classes_).issubset(set(true_labels)) == False:\n",
    "        break\n",
    "    cm = confusion_matrix(true_labels, predicted_labels,\n",
    "                          labels=al_model.classes_)\n",
    "    print(\"Iteration %i %s\" % (i, 70 * \"_\"))\n",
    "    \n",
    "        \n",
    "    print(\"Label Spreading model: %d labeled & %d unlabeled (%d total)\"\n",
    "          % (n_labeled_points, len(AL_Y) - n_labeled_points,\n",
    "             len(AL_Y)))\n",
    "\n",
    "    print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "    print(\"Confusion matrix\")\n",
    "    print(cm)\n",
    "\n",
    "    # compute the entropies of transduced label distributions\n",
    "    pred_entropies = stats.distributions.entropy(\n",
    "        al_model.label_distributions_.T)\n",
    "\n",
    "    # select up to 5 digit examples that the classifier is most uncertain about\n",
    "    uncertainty_index = np.argsort(pred_entropies)[::-1]\n",
    "    uncertainty_index = uncertainty_index[\n",
    "        np.in1d(uncertainty_index, unlabeled_indices)][:50]\n",
    "\n",
    "    # keep track of indices that we get labels for\n",
    "    delete_indices = np.array([])\n",
    "    \n",
    "    for index, check_index in enumerate(uncertainty_index):\n",
    "        check = AL_ftss[check_index]\n",
    "\n",
    "        delete_index, = np.where(unlabeled_indices == check_index)\n",
    "        delete_indices = np.concatenate((delete_indices, delete_index))\n",
    "\n",
    "    unlabeled_indices = np.delete(unlabeled_indices, delete_indices)\n",
    "    n_labeled_points += len(uncertainty_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb789a496a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f.suptitle(\"Active learning with Label Propagation.\\nRows show 50 most \"\n",
    "           \"uncertain labels to learn with the next model.\", y=1.15)\n",
    "plt.subplots_adjust(left=0.2, bottom=0.03, right=0.9, top=0.9, wspace=0.2,\n",
    "                    hspace=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

% Paper template for TAR 2018
% (C) 2014 Jan Šnajder, Goran Glavaš, Domagoj Alagić, Mladen Karan
% TakeLab, FER

\documentclass[10pt, a4paper]{article}

\usepackage{tar2018}

\usepackage[utf8]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}

\title{TAR System Description Paper Template}

\name{Stjepanović Mateo, Žabčić Mislav, Tolić Filip} 

\address{
University of Zagreb, Faculty of Electrical Engineering and Computing\\
Unska 3, 10000 Zagreb, Croatia\\ 
\texttt{mateo.stjepanovic@fer.hr}, \texttt{\{mislav.zabcic,filip.tolic\}@fer.hr}\\
}
          
         
\abstract{ 
This document provides the instructions on formatting the TAR system description paper in \LaTeX{}. This is where you write the abstract (i.e., summary) of the work you carried out within the project. The abstract is a paragraph of text ranging between 70 and 150 words.
}

\begin{document}

\maketitleabstract

\section{Introduction}

This section is the introduction to your paper. Introduction should not be too elaborate, as that is what other sections are for (the Introduction should definitely not spill over to the second page). 

This is the second paragraph of the introduction. In \LaTeX , paragraphs are separated by inserting an empty line in between them.  Avoid very large paragraphs (larger than half of the page height), but also avoid tiny paragraphs (e.g., one-sentence paragraphs).

\section{Related work}

Hate speech is great problem of today. Not many works has been done on this subject yet. From that reason we don't have dataset of set of features for hate speech. It is important to separate hate speech from offensive language, even so because of new laws against hate speech\cite{Davidson2017AutomatedHS}. Papers so far shows that best approach to given problem is using Support Vector Machine (SVM) and Bag-of-Words(BoW).\cite{Davidson2017AutomatedHS}.
\\Researchers tried to create topology for abusive language, which could help to specify features for identifying abusive language.\cite{WaseemUnderstandingAbuse} stated that there is four types of abusive language that one should take into account.
\begin{itemize}
	\item \textit{Directed Implicit}
	\item \textit{Generalized Implicit}
	\item \textit{Directed Explicit}
	\item \textit{Generalized Explicit}
\end{itemize}

In \cite{Davidson2017AutomatedHS} they used several features to capture information about syntactic and semantic structures. Porter stemmer is used to create unigram, bigram and trigram features and then used TF-IDF to put weights to them. Using NLTK they constructed Part of Speech tags as features. They showed that their model is working great, and got pretty high official metrics (precision, recall and F1 score).

\\\cite{ChenSVMFeatures} shows that one can implement feature selection methods into SVM it self. This could possibly make great future work in trying to achieve end-to-end solution for hate speech identification problem, as we encountered problem of high number of features, and high CPU and RAM requirement as result of that.
\\Giving the problem of difficulty to get relevant data and to manually annotate enough of them, active learning is developed. \cite{LuoALPlankton} proposed new active learning model based on multi-class support vector machines. They showed that there is a way to make SVM work with probabilities and give us proper active learning model. Even though we didn't implement this model, plan is to implement it in the future and test it on state-of-the-art models. Their algorithm works as follows:
\begin{itemize}
	\item 1. Start with an initial training set and an unclassified set.
	\item 2. A multi-class support vector machine is built using the current training set.
	\item 3. Compute the probabilistic outputs of the classification results for each data on the unclassified set. Suppose the class with highest probability is a and the class with second highest probability is b. Record the value of P(a) and P(b) for each unclassified data.
	\item 4. Remove the data from the unclassified set that have the smallest difference in probabilities between them (P(a) − P(b)) for the two highest probability classes, obtain the correct label from human experts and add the labeled data to the current training set.
	\item 5. Go to 2
\end{itemize}

\\In \cite{YangMultiClassAL} authors introduced their own active learning model based on multi-class SVMs. It is little different from one before on manner that they calculate probability on each data in unlabeled pool. Given that model is computational expensive if unlabeled pool in large size. Their experiment also show that they outperform state-of-the-art models, which can only be a sign to continue further on out work to get end-to-end solution for hate speech identification.
\bibliographystyle{tar2018}
\bibliography{tar2018} 

\end{document}

